{"end": true, "d": [{"q": "The great advance of personal computers was not the computing power per se but the fact that it brought it right to your face, that you had control over it, that were confronted with it and could steer it.", "d": {"d": ["Kevin Kelly", "Face", "You", "Great", "Power"], "i": [9531, 2567, 8278, 3222, 5651]}}, {"q": "Organisms by their design are not made to adapt too far.", "d": {"d": ["Kevin Kelly", "Adapt", "Far", "Made", "Too"], "i": [9531, 92, 2621, 4463, 7539]}}, {"q": "Species go extinct because there are historical contraints built into a given body or a given design.", "d": {"d": ["Kevin Kelly", "Body", "Historical", "Go", "Because"], "i": [9531, 812, 3510, 3090, 622]}}, {"q": "All imaginable futures are not equally possible.", "d": {"d": ["Kevin Kelly", "Possible", "Equally", "Imaginable", "Futures"], "i": [9531, 5641, 2406, 3718, 2965]}}, {"q": "An organization's intelligence is distributed to the point of being ubiquitous.", "d": {"d": ["Kevin Kelly", "Organization", "Being", "Point", "Ubiquitous"], "i": [9531, 5218, 650, 5579, 7730]}}, {"q": "This is actually a very important principle that science is learning about large systems like evolution and that futurists are learning about anticipating human society: just because a future scenario is plausible doesn't mean we can get there from here.", "d": {"d": ["Kevin Kelly", "Science", "Future", "Society", "Important"], "i": [9531, 6445, 2963, 6835, 3752]}}, {"q": "We are infected by our own misunderstanding of how our own minds work.", "d": {"d": ["Kevin Kelly", "Misunderstanding", "Own", "How", "Minds"], "i": [9531, 4732, 5278, 3591, 4692]}}]}